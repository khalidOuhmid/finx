version: '3.8'

services:
  cassandra:
    image: cassandra:5.0
    ports:
      - "9042:9042"
    environment:
      - CASSANDRA_CLUSTER_NAME=SparkCluster
      - JVM_EXTRA_OPTS=-XX:+UseZGC -Xms2G -Xmx4G
    healthcheck:
      test: ["CMD-SHELL", "cqlsh -e 'DESCRIBE KEYSPACES'"]
      interval: 10s
      timeout: 5s
      retries: 10

  spark-master:
    image: eclipse-temurin:21-jdk
    command: >
      /bin/sh -c "
      apt-get update && apt-get install -y python3 &&
      wget https://archive.apache.org/dist/spark/spark-4.0.0-preview2/spark-4.0.0-preview2-bin-hadoop3.tgz &&
      tar -xzf spark-4.0.0-preview2-bin-hadoop3.tgz &&
      ./spark-4.0.0-preview2-bin-hadoop3/sbin/start-master.sh -h 0.0.0.0 --port 7077 --webui-port 8080 &&
      tail -f /dev/null"
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_LOCAL_IP=spark-master
      - JAVA_HOME=/opt/java/openjdk
      - SPARK_MASTER_HOST=spark-master
      - SPARK_JAVA_OPT_OVERRIDES=-XX:+UseZGC -Xmx8g
    depends_on:
      cassandra:
        condition: service_healthy

  spring-app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8081:8080"
    environment:
      - SPRING_DATA_CASSANDRA_CONTACTPOINTS=cassandra
      - SPRING_PROFILES_ACTIVE=docker
    depends_on:
      spark-master:
        condition: service_started

volumes:
  cassandra-data:
  spark-logs:

networks:
  spark-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
